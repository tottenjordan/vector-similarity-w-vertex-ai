{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4520327-c600-4dce-95c9-ec4da949cc3a",
   "metadata": {},
   "source": [
    "## Instructions for downloading and preparing the [Kaggle Retail Products Classification](https://www.kaggle.com/competitions/retail-products-classification/data) dataset\n",
    "\n",
    "* Visual Similarity, Matching Engine, Vetex Pipeline [Colab](https://colab.sandbox.google.com/drive/1ysjjGTv7EKkBD90dsdVD3OZvW4Oka1aC#scrollTo=_9U0deUAtD_A)\n",
    "\n",
    "* **Note: if you are creating a Notebook instance and plan to execute vector matching online queries** with Vertex Matching Engine:\n",
    "> * be sure the Notebook instance's network matches the **VPC created for Matching Engine** \n",
    "> * See [here](https://cloud.google.com/vertex-ai/docs/matching-engine/match-eng-setup#vpc-network-peering-setup) if you don't know what this means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154f8918-ca74-4885-a295-b3e10f2f8c99",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "518e7329-1efa-4c1f-83f8-d5a6628c7d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROJECT_ID = 'hybrid-vertex'  # <--- TODO: CHANGE THIS\n",
    "# LOCATION = 'us-central1' \n",
    "# !gcloud config set project {PROJECT_ID}\n",
    "\n",
    "import sys\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a67914-9127-49b4-a7d6-6e49451d85d2",
   "metadata": {},
   "source": [
    "If using Google Colab..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0a9346e-b744-4df2-a395-7842edcb194d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in sys.modules:\n",
    "    USER_FLAG = ''\n",
    "else:\n",
    "    USER_FLAG = '--user'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d8a9363-55fd-4aa8-bff1-eb926d9a8b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KEEP: packages needed\n",
    "!pip install -U google-cloud-aiplatform $USER_FLAG\n",
    "!pip3 install -U google-cloud-storage $USER_FLAG\n",
    "\n",
    "\n",
    "# Automatically restart kernel after installs\n",
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15c1c127-2ec1-4f93-8cfc-eba5c59dea62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aiplatform SDK version: 1.18.1\n"
     ]
    }
   ],
   "source": [
    "! python3 -c \"import google.cloud.aiplatform; print('aiplatform SDK version: {}'.format(google.cloud.aiplatform.__version__))\"\n",
    "# >= 1.16.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e104b6bb-385a-4b2a-86b7-ec85fa626332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "\n",
      "\n",
      "To take a quick anonymous survey, run:\n",
      "  $ gcloud survey\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = 'hybrid-vertex'  # <--- TODO: CHANGE THIS\n",
    "LOCATION = 'us-central1' \n",
    "!gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51279baf-0b93-4b99-88d5-dd52d162e711",
   "metadata": {},
   "source": [
    "### Pip & Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f487c90d-1bd9-478b-b7d9-f70eac3e20dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "# import scann\n",
    "\n",
    "from IPython.display import clear_output, Image\n",
    "from IPython.core.display import HTML \n",
    "\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "# from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "\n",
    "from google import auth\n",
    "# from google.colab import auth as colab_auth # if using Colab\n",
    "# colab_auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4384d467-3f05-452b-a4f0-e8a8128f981d",
   "metadata": {},
   "source": [
    "### Setup Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94133367-512a-4ffb-ad58-cd722341adfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_CLOUD_PROJECT']=PROJECT_ID\n",
    "\n",
    "# bq_client = bigquery.Client(project=PROJECT_ID, credentials=CREDENTIALS)\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "vertex_ai.init(project=PROJECT_ID,location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e84b715-ce49-415b-a256-e4ab71f254e4",
   "metadata": {},
   "source": [
    "## Kaggle Retail Product Classification\n",
    "\n",
    "Download the Kaggle [Retail Product Dataset](https://www.kaggle.com/c/retail-products-classification/data) and upload the zip to a Cloud Storage Bucket\n",
    "* 42,000 product images and short descriptions\n",
    "* 21 product categories\n",
    "* Image dims = 100x100\n",
    "* CSV includes\n",
    "> * `title`: Name of product\n",
    "> * `description`: short description of the product\n",
    "> * `category`: name of the category the product belongs to\n",
    "\n",
    "TODO:\n",
    "* Create text embeddings for description, title, category, and Vision API tags (e.g., OCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29b26c6-ea52-4635-9119-029fdfdd3fd0",
   "metadata": {},
   "source": [
    "## Inspect CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da975389-e458-4806-b0cd-59b3bc0c0395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImgId</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B0006IK25E</td>\n",
       "      <td>Jacquard Textile Paint 2.25 Oz Pink</td>\n",
       "      <td>Jacquard Textile Pink Color in 2.25 ounces can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B000GBRO16</td>\n",
       "      <td>Fimo Soft Polymer Clay 2 Ounces-8020-33 Brilli...</td>\n",
       "      <td>Fimo Soft Polymer Clay is easier to use than b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000H6OZGW</td>\n",
       "      <td>Sculpey III 2 Oz. Polymer Clay: Pale Pistachio</td>\n",
       "      <td>Sculpey 3 Polymer Clay is America's original o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000BR28KC</td>\n",
       "      <td>Sennelier Soft Pastel Turquoise Green 724</td>\n",
       "      <td>Handmade since 1900 Sennelier extra-fine soft ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B0006IK27M</td>\n",
       "      <td>Jacquard Textile Colors sapphire blue</td>\n",
       "      <td>JACQUARD TEXTILE COLORS FABRIC PAINT - These e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ImgId                                              title  \\\n",
       "0  B0006IK25E                Jacquard Textile Paint 2.25 Oz Pink   \n",
       "1  B000GBRO16  Fimo Soft Polymer Clay 2 Ounces-8020-33 Brilli...   \n",
       "2  B000H6OZGW     Sculpey III 2 Oz. Polymer Clay: Pale Pistachio   \n",
       "3  B000BR28KC          Sennelier Soft Pastel Turquoise Green 724   \n",
       "4  B0006IK27M              Jacquard Textile Colors sapphire blue   \n",
       "\n",
       "                                         description  \n",
       "0  Jacquard Textile Pink Color in 2.25 ounces can...  \n",
       "1  Fimo Soft Polymer Clay is easier to use than b...  \n",
       "2  Sculpey 3 Polymer Clay is America's original o...  \n",
       "3  Handmade since 1900 Sennelier extra-fine soft ...  \n",
       "4  JACQUARD TEXTILE COLORS FABRIC PAINT - These e...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_CSV_URI = 'gs://retail-products-kaggle/data-full/test.csv'\n",
    "test_csv = pd.read_csv(test_CSV_URI)\n",
    "test_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ffbd281-9974-4fe0-9ad6-f4f111651149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImgId</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B000HYL1V6</td>\n",
       "      <td>TUNGSTEN SOLDER PICK WITH HANDLE</td>\n",
       "      <td>Solder Pick for picking up molten solder when ...</td>\n",
       "      <td>Arts, Crafts &amp; Sewing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00006HXWY</td>\n",
       "      <td>Write Right 98167 Screen Protector for Sony T615C</td>\n",
       "      <td>We all screen. And we all need to protect thos...</td>\n",
       "      <td>Cell Phones &amp; Accessories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000GAWSBS</td>\n",
       "      <td>Casio Mens DBC310-1 Databank 300 Digital Watch...</td>\n",
       "      <td>Bringing you precision at a glance, the Casio ...</td>\n",
       "      <td>Clothing, Shoes &amp; Jewelry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000040JOL</td>\n",
       "      <td>Factory-Reconditioned DEWALT DW260KR Heavy-Dut...</td>\n",
       "      <td>Factory-Reconditioned DEWALT DW260KR Heavy-Dut...</td>\n",
       "      <td>Tools &amp; Home Improvement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00006IB78</td>\n",
       "      <td>Energizer 2 in 1 Light</td>\n",
       "      <td>This twoway light features a bright flashlight...</td>\n",
       "      <td>Health &amp; Personal Care</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ImgId                                              title  \\\n",
       "0  B000HYL1V6                   TUNGSTEN SOLDER PICK WITH HANDLE   \n",
       "1  B00006HXWY  Write Right 98167 Screen Protector for Sony T615C   \n",
       "2  B000GAWSBS  Casio Mens DBC310-1 Databank 300 Digital Watch...   \n",
       "3  B000040JOL  Factory-Reconditioned DEWALT DW260KR Heavy-Dut...   \n",
       "4  B00006IB78                             Energizer 2 in 1 Light   \n",
       "\n",
       "                                         description  \\\n",
       "0  Solder Pick for picking up molten solder when ...   \n",
       "1  We all screen. And we all need to protect thos...   \n",
       "2  Bringing you precision at a glance, the Casio ...   \n",
       "3  Factory-Reconditioned DEWALT DW260KR Heavy-Dut...   \n",
       "4  This twoway light features a bright flashlight...   \n",
       "\n",
       "                  categories  \n",
       "0      Arts, Crafts & Sewing  \n",
       "1  Cell Phones & Accessories  \n",
       "2  Clothing, Shoes & Jewelry  \n",
       "3   Tools & Home Improvement  \n",
       "4     Health & Personal Care  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_CSV_URI = 'gs://retail-products-kaggle/data-full/train.csv'\n",
    "train_csv = pd.read_csv(train_CSV_URI)\n",
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de62e60e-0eca-4dfe-8d4d-d3e975419e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImgId</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7326</th>\n",
       "      <td>097585562X</td>\n",
       "      <td>TableTopics Teen</td>\n",
       "      <td>Dismayed by the silence around your dinner tab...</td>\n",
       "      <td>Toys &amp; Games</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ImgId             title  \\\n",
       "7326  097585562X  TableTopics Teen   \n",
       "\n",
       "                                            description    categories  \n",
       "7326  Dismayed by the silence around your dinner tab...  Toys & Games  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_ID = '097585562X'\n",
    "\n",
    "train_csv.loc[train_csv['ImgId'].str.contains(IMAGE_ID, case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "743128ec-1f5e-447e-8704-d8161edc651f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids = train_csv['ImgId']\n",
    "# cats = train_csv['categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe71603d-fca5-48b2-8cd3-4587b7f7d5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7326    Toys & Games\\nName: categories, dtype: object'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat = train_csv.loc[train_csv['ImgId'].str.contains(IMAGE_ID, case=False)]['categories']\n",
    "str(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48c777bb-7ee6-4b06-bbdd-72cf11745766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Toys & Games'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat = train_csv.loc[train_csv['ImgId'] == IMAGE_ID, 'categories'].item()\n",
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7f2ebf6-8cfb-478c-b6d8-9e713f07f621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Arts, Crafts & Sewing        2225\n",
       "Beauty                       2202\n",
       "Grocery & Gourmet Food       2201\n",
       "Sports & Outdoors            2201\n",
       "Automotive                   2200\n",
       "Industrial & Scientific      2200\n",
       "Musical Instruments          2200\n",
       "Appliances                   2200\n",
       "Office Products              2200\n",
       "All Beauty                   2200\n",
       "Toys & Games                 2200\n",
       "Electronics                  2200\n",
       "All Electronics              2200\n",
       "Cell Phones & Accessories    2200\n",
       "Patio, Lawn & Garden         2200\n",
       "Baby                         2200\n",
       "Baby Products                2200\n",
       "Health & Personal Care       2200\n",
       "Tools & Home Improvement     2200\n",
       "Clothing, Shoes & Jewelry    2200\n",
       "Pet Supplies                 2200\n",
       "Name: categories, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_counts = train_csv['categories'].value_counts()\n",
    "category_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148dd64a-45ea-427a-af84-36804b55fe79",
   "metadata": {},
   "source": [
    "### Unzip the files and store in Cloud Storage bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b30b0c7e-b75b-44de-88e8-0fc008254fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = 'retail-products-kaggle'\n",
    "ZIP_PATH = 'retail-products-classification.zip' # if the file is gs://$BUCKET/retail-products-classification.zip\n",
    "DEST_FOLDER = 'data-full' # folder to place unzipped files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d2b76e0-de6f-487d-bfe4-dfe30d50002d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "from zipfile import ZipFile\n",
    "from zipfile import is_zipfile\n",
    "import io\n",
    "\n",
    "def zipextract(bucketname, zipfilename_with_path, destination_folder):\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(bucketname)\n",
    "\n",
    "    destination_blob_pathname = zipfilename_with_path\n",
    "    \n",
    "    blob = bucket.blob(destination_blob_pathname)\n",
    "    zipbytes = io.BytesIO(blob.download_as_string())\n",
    "\n",
    "    if is_zipfile(zipbytes):\n",
    "        with ZipFile(zipbytes, 'r') as myzip:\n",
    "            for contentfilename in myzip.namelist():\n",
    "                contentfile = myzip.read(contentfilename)\n",
    "                blob = bucket.blob(destination_folder + \"/\" + contentfilename)\n",
    "                blob.upload_from_string(contentfile)\n",
    "\n",
    "# zipextract(\"mybucket\", \"path/file.zip\") # if the file is gs://mybucket/path/file.zip\n",
    "zipextract(BUCKET, ZIP_PATH, DEST_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6a07c8-a124-4187-81ae-42eeefafacb1",
   "metadata": {},
   "source": [
    "### Count files in GCS bucket\n",
    "\n",
    "* Train Images = 42,001\n",
    "* Test Images = 6368"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "135c40e9-9cee-4037-93fe-5ba71079e5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42001\n"
     ]
    }
   ],
   "source": [
    "# !gsutil du gs://retail-products-kaggle/data-full/train/train | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "313b3fcb-5076-4120-bc59-d45c72eed11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6368\n"
     ]
    }
   ],
   "source": [
    "# !gsutil du gs://retail-products-kaggle/data-full/test/test | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a108043-251d-4165-887f-9ff0f029caee",
   "metadata": {},
   "source": [
    "### Test: compute embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c22c0192-00f4-4003-a4d9-d765c715fb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://retail-products-kaggle/retail-products-classification.zip\n",
      "gs://retail-products-kaggle/data-full/\n",
      "gs://retail-products-kaggle/dataset/\n",
      "gs://retail-products-kaggle/indexes/\n",
      "gs://retail-products-kaggle/pipeline_root/\n",
      "gs://retail-products-kaggle/saved-models/\n"
     ]
    }
   ],
   "source": [
    "IMAGE_DIR = f'gs://{BUCKET}'\n",
    "!gsutil ls $IMAGE_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac233a82-d858-49cf-b1f9-11f5a812c54e",
   "metadata": {},
   "source": [
    "#### Validate image files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0965fd87-4858-47da-9594-d6d8166256fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gs://retail-products-kaggle/data-full/train/train/097924837X.jpg\n",
    "# FILE_NAME = f'{DEST_FOLDER}/train/train/097585562X.jpg'\n",
    "FILE_NAME = f'{DEST_FOLDER}/train/train/097924837X.jpg'\n",
    "\n",
    "bucket = storage_client.get_bucket(BUCKET)\n",
    "blob = bucket.blob(FILE_NAME)\n",
    "Image(blob.download_as_bytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467850f0-528d-4813-91d3-7de109a1a00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_and_decode_v2(filename, reshape_dims=[IMG_HEIGHT, IMG_WIDTH]):\n",
    "#   # Read the file\n",
    "#   img = tf.io.read_file(filename)\n",
    "  \n",
    "#   # Convert the compressed string to a 3D uint8 tensor.\n",
    "#   img = tf.image.decode_jpeg(img, channels=IMG_CHANNELS)\n",
    "  \n",
    "#   # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "#   # This makes the img 1 x 224 x 224 x 3 tensor with the data type of float32\n",
    "#   img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "  \n",
    "#   # Resize the image to the desired size.\n",
    "#   return tf.image.resize(img, reshape_dims)\n",
    "\n",
    "# f, ax = plt.subplots(len(query_filenames), NUM_NEIGH + 1,\n",
    "#                      figsize=(5 * (1 + NUM_NEIGH), 5 * len(query_filenames)))\n",
    "# for rowno, query_filename in enumerate(query_filenames):\n",
    "#   ax[rowno][0].imshow(read_and_decode_v2(query_filename).numpy())\n",
    "#   ax[rowno][0].axis('off')\n",
    "#   for colno, neigh in enumerate(neighbors[rowno]):\n",
    "#     ax[rowno][colno+1].imshow(read_and_decode_v2(dataset_filenames[neigh]).numpy())\n",
    "#     ax[rowno][colno+1].set_title('dist={:.1f}'.format(distances[rowno][colno].numpy()))\n",
    "#     ax[rowno][colno+1].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc63126-02a7-4ded-b4bb-2862cf709a90",
   "metadata": {},
   "source": [
    "## Load compressed model from tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57bb3b9e-5e44-4a60-952c-125b30e326f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TFHUB_MODEL_LOAD_FORMAT'] = 'COMPRESSED'\n",
    "\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "IMG_CHANNELS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332e5756-7e13-4ff7-8dee-b73c5c3c1fbe",
   "metadata": {},
   "source": [
    "### Read and decode image - return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c8a3339-d07f-4dcd-a646-bbc87f30824c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_decode(filename, reshape_dims=[IMG_HEIGHT, IMG_WIDTH]):\n",
    "    # Read the file\n",
    "    img = tf.io.read_file(filename)\n",
    "  \n",
    "    # Convert the compressed string to a 3D uint8 tensor.\n",
    "    img = tf.image.decode_jpeg(img, channels=IMG_CHANNELS)\n",
    "  \n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "    # This makes the img 1 x 224 x 224 x 3 tensor with the data type of float32\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n",
    "  \n",
    "    # Resize the image to the desired size.\n",
    "    return tf.image.resize(img, reshape_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69b9e3a2-c6ab-49f1-9644-c9f99d4e61b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 224, 224, 3), dtype=float32, numpy=\n",
       "array([[[[0.9960785, 0.9960785, 0.9960785],\n",
       "         [0.9960785, 0.9960785, 0.9960785],\n",
       "         [0.9960785, 0.9960785, 0.9960785],\n",
       "         ...,\n",
       "         [0.9960785, 0.9960785, 0.9960785],\n",
       "         [0.9960785, 0.9960785, 0.9960785],\n",
       "         [0.9960785, 0.9960785, 0.9960785]],\n",
       "\n",
       "        [[0.9960785, 0.9960785, 0.9960785],\n",
       "         [0.9960785, 0.9960785, 0.9960785],\n",
       "         [0.9960785, 0.9960785, 0.9960785],\n",
       "         ...,\n",
       "         [0.9960785, 0.9960785, 0.9960785],\n",
       "         [0.9960785, 0.9960785, 0.9960785],\n",
       "         [0.9960785, 0.9960785, 0.9960785]],\n",
       "\n",
       "        [[0.9960785, 0.9960785, 0.9960785],\n",
       "         [0.9960785, 0.9960785, 0.9960785],\n",
       "         [0.9960785, 0.9960785, 0.9960785],\n",
       "         ...,\n",
       "         [0.9960785, 0.9960785, 0.9960785],\n",
       "         [0.9960785, 0.9960785, 0.9960785],\n",
       "         [0.9960785, 0.9960785, 0.9960785]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.9960785, 0.9960785, 0.9960785],\n",
       "         [0.9960785, 0.9960785, 0.9960785],\n",
       "         [0.9960785, 0.9960785, 0.9960785],\n",
       "         ...,\n",
       "         [0.9960785, 0.9960785, 0.9960785],\n",
       "         [0.9960785, 0.9960785, 0.9960785],\n",
       "         [0.9960785, 0.9960785, 0.9960785]],\n",
       "\n",
       "        [[0.9960785, 0.9960785, 0.9960785],\n",
       "         [0.9960785, 0.9960785, 0.9960785],\n",
       "         [0.9960785, 0.9960785, 0.9960785],\n",
       "         ...,\n",
       "         [0.9960785, 0.9960785, 0.9960785],\n",
       "         [0.9960785, 0.9960785, 0.9960785],\n",
       "         [0.9960785, 0.9960785, 0.9960785]],\n",
       "\n",
       "        [[0.9960785, 0.9960785, 0.9960785],\n",
       "         [0.9960785, 0.9960785, 0.9960785],\n",
       "         [0.9960785, 0.9960785, 0.9960785],\n",
       "         ...,\n",
       "         [0.9960785, 0.9960785, 0.9960785],\n",
       "         [0.9960785, 0.9960785, 0.9960785],\n",
       "         [0.9960785, 0.9960785, 0.9960785]]]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_IMG_PATH = f'gs://{BUCKET}/{FILE_NAME}'\n",
    "read_and_decode(TEST_IMG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0131831-09c1-402d-9071-fb43fc011f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_HUB_MODEL_DIR = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89551464-1986-4eed-9ad1-2bbecd78c9d6",
   "metadata": {},
   "source": [
    "### Downalod TF Hub model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d724c89c-554f-463c-a334-57d3ebee5a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"visual_embedding\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenet_embedding (KerasL  (None, 1280)             2257984   \n",
      " ayer)                                                           \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1280)              0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,257,984\n",
      "Trainable params: 0\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "layers = [\n",
    "      hub.KerasLayer(\n",
    "          f\"{TF_HUB_MODEL_DIR}\",\n",
    "          input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),\n",
    "          trainable=False,\n",
    "          name='mobilenet_embedding'),\n",
    "      tf.keras.layers.Flatten()\n",
    "]\n",
    "model = tf.keras.Sequential(\n",
    "    layers, name='visual_embedding'\n",
    ")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7945cc-8bc2-4bad-8cfe-25bfc6991c9d",
   "metadata": {},
   "source": [
    "# Create embeddings dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9a350b7-7830-4854-b203-a7616c65cf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "def create_embeddings_dataset(embedder, img_path):\n",
    "    dataset_filenames = []\n",
    "    dataset_embeddings = []\n",
    "    list_dir = tf.io.gfile.listdir(img_path)\n",
    "    for file in list_dir[:50]: # test\n",
    "        img_tensor = read_and_decode(img_path + \"/\" + file, [IMG_WIDTH, IMG_HEIGHT])\n",
    "        embeddings = embedder(img_tensor)\n",
    "        dataset_filenames.append(img_path + \"/\" + file)\n",
    "        dataset_embeddings.extend(embeddings)\n",
    "  \n",
    "    dataset_embeddings = tf.convert_to_tensor(dataset_embeddings)\n",
    "  \n",
    "    return dataset_filenames, dataset_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47e29c93-4c0b-4207-bbd0-e8f1fa9d6109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gs://retail-products-kaggle/data-full/train/train/097585562X.jpg', 'gs://retail-products-kaggle/data-full/train/train/097924837X.jpg', 'gs://retail-products-kaggle/data-full/train/train/097965856X.jpg']\n",
      "(50, 1280)\n"
     ]
    }
   ],
   "source": [
    "IMG_PATH = f'gs://{BUCKET}/{DEST_FOLDER}/train/train'\n",
    "\n",
    "dataset_filenames, dataset_embeddings = create_embeddings_dataset(\n",
    "    lambda x: model.predict(x),\n",
    "    IMG_PATH\n",
    ")\n",
    "\n",
    "print(dataset_filenames[:3])\n",
    "print(dataset_embeddings.shape) # should be (NUM_IMAGES, 1280)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d59c00e-cd06-4639-81b2-b7ee2b6c652e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_embeddings = []\n",
    "\n",
    "for file in list_dir:\n",
    "    img_tensor = read_and_decode(img_path)\n",
    "    embeddings = embedder(img_tensor)\n",
    "    dataset_filenames.append(img_path + \"/\" + file)\n",
    "    dataset_embeddings.extend(embeddings)\n",
    "\n",
    "dataset_embeddings = tf.convert_to_tensor(dataset_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcc6ee7-4740-4b0f-8663-bffdb40b3980",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_PATH = f'gs://{BUCKET}/{DEST_FOLDER}/train/train'\n",
    "\n",
    "dataset_filenames, dataset_embeddings = create_embeddings_dataset(\n",
    "    lambda x: model.predict(x),\n",
    "    IMG_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1450ee-2901-4bb8-aa64-34ba113baedc",
   "metadata": {},
   "source": [
    "## Test writting `json` for index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0bc5e61-225c-43c9-988b-3e93117a3d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://retail-products-kaggle/data-full/train/train/097585562X.jpg'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_IMG_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5fde0d27-03ac-46d3-8b2c-d88221bc86c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcs_uri: gs://retail-products-kaggle/data-full/train/train/097585562X.jpg\n",
      "x: 097585562X.jpg\n",
      "id_: 097585562X\n"
     ]
    }
   ],
   "source": [
    "gcs_uri =f'{TEST_IMG_PATH}'\n",
    "print(f'gcs_uri: {gcs_uri}')\n",
    "\n",
    "x = gcs_uri.split(\"/\")[-1]\n",
    "print(f'x: {x}')\n",
    "\n",
    "id_ = x.split(\".\")[0]\n",
    "print(f'id_: {id_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9294bf52-3878-4733-97ae-ee005812ca75",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"test.json\", \"w\") as f:\n",
    "    for gcs_uri, vector in zip(dataset_filenames,dataset_embeddings):\n",
    "        x = gcs_uri.split(\"_\")[-1]\n",
    "        id_ = x.split(\".\")[0]\n",
    "        vector = vector.numpy()\n",
    "        f.write('{\"id\":\"' + str(id_) + '\",')\n",
    "        f.write('\"embedding\":[' + \",\".join(str(x) for x in vector) + \"]}\")\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27c4cfc-c74f-4bf8-a979-46f984e6c6cc",
   "metadata": {},
   "source": [
    "# Create Query Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7cafe3e0-c37a-4440-90f1-558249534bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TEST_SAMPLES = 50\n",
    "EVAL_IMG_PATH = f'gs://{BUCKET}/{DEST_FOLDER}/test/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6aedb39-aa75-4001-9788-96941fc84bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_query_embeddings(embedder, img_path, num_test_samples):\n",
    "    dataset_filenames = []\n",
    "    dataset_embeddings = []\n",
    "  \n",
    "    list_dir = tf.io.gfile.listdir(img_path)\n",
    "  \n",
    "    for file in list_dir[:num_test_samples]:\n",
    "        img_tensor = read_and_decode(img_path + \"/\" + file, [IMG_WIDTH, IMG_HEIGHT])\n",
    "        embeddings = embedder(img_tensor)\n",
    "        dataset_filenames.append(img_path + \"/\" + file)\n",
    "        dataset_embeddings.extend(embeddings)\n",
    "  \n",
    "    dataset_embeddings = tf.convert_to_tensor(dataset_embeddings)\n",
    "  \n",
    "    return dataset_filenames, dataset_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "438b300a-3390-41ad-9f38-61c11971ca16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_embeddings shape: (50, 1280)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.08451159, 0.        , 0.00108564, ..., 0.3638365 , 0.11259918,\n",
       "       0.        ], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_filenames, query_embeddings = create_query_embeddings(\n",
    "    lambda x: model.predict(x),\n",
    "    EVAL_IMG_PATH,\n",
    "    NUM_TEST_SAMPLES\n",
    ")\n",
    "\n",
    "vector_list = []\n",
    "for q_vector in query_embeddings:\n",
    "    vector_list.append(q_vector.numpy())\n",
    "\n",
    "# print(\"query_filenames:\", query_filenames)\n",
    "print(\"query_embeddings shape:\", query_embeddings.shape) # should be (NUM_TEST_SAMPLES, 1280)\n",
    "# print(\"vector_list shape:\", vector_list.shape)\n",
    "\n",
    "vector_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15284b9b-de04-482b-b1a0-f014afcdc1af",
   "metadata": {},
   "source": [
    "## List Index Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5482bd17-3c01-4705-afac-b4b29fbed2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "Listed 0 items.\n"
     ]
    }
   ],
   "source": [
    "!gcloud beta ai index-endpoints list --project=\"hybrid-vertex\" --region=us-central1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a5e46c-ebc6-4822-93f5-76a250b81ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_endpoint_resource_uri = 'projects/163017677720/locations/us-central1/indexEndpoints/5129564791202906112'\n",
    "\n",
    "index_endpoint = vertex_ai.MatchingEngineIndexEndpoint(index_endpoint_resource_uri)\n",
    "\n",
    "NUM_NEIGH = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea0e678-2ca2-4ed8-bde8-165fd95ad614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29e86ab-a087-4fcb-b8ba-2304acc63754",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0557baba-c1f7-4946-9c92-e63d7cc02654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca1e4f7-c4f2-4510-877a-f93208474231",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m95",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m95"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
