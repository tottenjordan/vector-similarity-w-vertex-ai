{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a620355-12e8-4683-ba7c-fae5162b1598",
   "metadata": {},
   "source": [
    "# Pipeline deployments for scaling experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3a1c307-9d8c-4789-ad3e-79598c443493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFP SDK version: 1.8.13\n",
      "google_cloud_pipeline_components version: 1.0.17\n",
      "aiplatform SDK version: 1.18.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install google-cloud-pipeline-components\n",
    "\n",
    "! python3 -c \"import kfp; print('KFP SDK version: {}'.format(kfp.__version__))\"\n",
    "! python3 -c \"import google_cloud_pipeline_components; print('google_cloud_pipeline_components version: {}'.format(google_cloud_pipeline_components.__version__))\"\n",
    "! python3 -c \"import google.cloud.aiplatform; print('aiplatform SDK version: {}'.format(google.cloud.aiplatform.__version__))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ddc9973c-2cc6-4e18-84ce-48027cb307d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = 'hybrid-vertex' \n",
    "LOCATION = 'us-central1' \n",
    "VERTEX_SA = '934903580331-compute@developer.gserviceaccount.com'\n",
    "\n",
    "!gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0dd1e1ae-5a85-4800-a00c-054625034f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "# Display Images\n",
    "from IPython.display import clear_output, Image\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "from google.cloud import storage\n",
    "\n",
    "# Pipelines\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "from google_cloud_pipeline_components.types import artifact_types\n",
    "\n",
    "# Kubeflow SDK\n",
    "# TODO: fix these\n",
    "from kfp.v2 import dsl\n",
    "import kfp\n",
    "import kfp.v2.dsl\n",
    "from kfp.v2.google import client as pipelines_client\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, component)\n",
    "\n",
    "\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "vertex_ai.init(project=PROJECT_ID,location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3960450-9636-40f9-87b7-8e044b4b5c74",
   "metadata": {},
   "source": [
    "## setup pipeline repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b39488c-f8e6-4c00-82b8-b95a38f49e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/retail-visual-similarity'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list the current work dir\n",
    "os.chdir('/home/jupyter/retail-visual-similarity')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "04c084fd-41e6-4c68-915f-0a40d5ebcce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIPELINES_FILEPATH: gs://retail-products-kaggle/pipelines_root/v5/run-20221104003701\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "# Optional: save and load pipeline definition\n",
    "PIPELINES = {}\n",
    "\n",
    "VERSION = 'v5'  # component code\n",
    "RUN = f'run-{TIMESTAMP}'\n",
    "PIPELINE_ROOT = 'pipelines_root'\n",
    "BUCKET = 'retail-products-kaggle'\n",
    "BUCKET_URI = f'gs://{BUCKET}'\n",
    "DATA_FOLDER = 'data-full'\n",
    "# DATA_FOLDER = 'dataset' # train_dir subset\n",
    "\n",
    "PIPELINES_FILEPATH = f'gs://{BUCKET}/{PIPELINE_ROOT}/{VERSION}/{RUN}' # /pipelines.json'\n",
    "print(\"PIPELINES_FILEPATH:\", PIPELINES_FILEPATH)\n",
    "\n",
    "if os.path.isfile(PIPELINES_FILEPATH):\n",
    "    with open(PIPELINES_FILEPATH) as f:\n",
    "        PIPELINES = json.load(f)\n",
    "else:\n",
    "    PIPELINES = {}\n",
    "\n",
    "def save_pipelines():\n",
    "    with open(PIPELINES_FILEPATH, 'w') as f:\n",
    "        json.dump(PIPELINES, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e4cf5488-ca66-443e-8e75-4ca1c6ea16e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_DOCKER_PATH_PREFIX = 'src'\n",
    "PIPELINES_SUB_DIR = 'pipes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1f703c3-1226-411d-b5cd-2b714a0244dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf {REPO_DOCKER_PATH_PREFIX}\n",
    "! mkdir {REPO_DOCKER_PATH_PREFIX}\n",
    "\n",
    "# ! rm -rf {REPO_DOCKER_PATH_PREFIX}/{PIPELINE_SUB_DIR}\n",
    "! mkdir {REPO_DOCKER_PATH_PREFIX}/{PIPELINES_SUB_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9196ef4-8d65-4073-8dce-5384166e22a6",
   "metadata": {},
   "source": [
    "# Pipe Components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837d4c64-bfd7-4a3c-a506-358568ecf7cd",
   "metadata": {},
   "source": [
    "## Generate candidate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "37fb31fd-8059-4616-9858-111d2d5e0fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/pipes/generate_candidates.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{PIPELINES_SUB_DIR}/generate_candidates.py\n",
    "\n",
    "import kfp\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, component, Metrics)\n",
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=[\n",
    "        'pandas==1.3.5',\n",
    "        'gcsfs',\n",
    "        'fsspec',\n",
    "        'google-cloud-aiplatform==1.18.1',\n",
    "        'google-cloud-storage',\n",
    "        'tensorflow==2.8',\n",
    "        'tensorflow-hub==0.12.0',\n",
    "        # 'tensorflow-estimator==2.8.0',\n",
    "        # 'keras==2.8.0'\n",
    "    ],\n",
    ")\n",
    "def generate_candidates(\n",
    "    project: str,\n",
    "    # run: str,\n",
    "    location: str,\n",
    "    version: str,\n",
    "    bucket: str, \n",
    "    dest_folder: str,\n",
    "    images_gcs_uri: str,\n",
    "    emb_index_gcs_uri: str,\n",
    "    index_json_name: str,\n",
    ") -> NamedTuple('Outputs', [\n",
    "    ('embedding_index_file_uri', str),\n",
    "    ('embedding_index_gcs_dir', str),\n",
    "    # ('saved_pretrained_model_gcs_location', str),\n",
    "]):\n",
    "    import os\n",
    "    import os.path\n",
    "    import time\n",
    "    import logging\n",
    "    import pandas as pd\n",
    "    \n",
    "    from google.cloud import aiplatform as vertex_ai\n",
    "    from google.cloud import storage\n",
    "    from google.cloud.storage.bucket import Bucket\n",
    "    from google.cloud.storage.blob import Blob\n",
    "    \n",
    "    \n",
    "    from datetime import datetime\n",
    "    import tensorflow as tf\n",
    "    import tensorflow_hub as hub\n",
    "    \n",
    "    os.environ['TFHUB_MODEL_LOAD_FORMAT'] = 'COMPRESSED'\n",
    "    TF_HUB_MODEL_DIR = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
    "\n",
    "    IMG_HEIGHT = 224\n",
    "    IMG_WIDTH = 224\n",
    "    IMG_CHANNELS = 3\n",
    "    \n",
    "    FILTER_INDEX_DIR = f'gs://{bucket}/indexes/{version}'\n",
    "    \n",
    "    IMG_PATH = f'gs://{bucket}/{dest_folder}/train/train'\n",
    "    logging.info(f'IMG_PATH: {IMG_PATH}')\n",
    "    LIST_DIR = tf.io.gfile.listdir(IMG_PATH)\n",
    "    logging.info(f'Length of LIST_DIR: {len(LIST_DIR)}')\n",
    "    \n",
    "    CSV_URI = f'gs://{bucket}/{dest_folder}/train.csv'\n",
    "    train_csv = pd.read_csv(CSV_URI)\n",
    "    logging.info(f'CSV_URI: {CSV_URI}')\n",
    "    \n",
    "    vertex_ai.init(\n",
    "        project=project,\n",
    "        location=location,\n",
    "    )\n",
    "    \n",
    "    # ==============================================================================\n",
    "    # Define helper functions\n",
    "    # ==============================================================================\n",
    "    def _upload_blob_gcs(gcs_uri, source_file_name, destination_blob_name):\n",
    "        \"\"\"Uploads a file to GCS bucket\"\"\"\n",
    "        client = storage.Client(project=project)\n",
    "        blob = Blob.from_string(os.path.join(gcs_uri, destination_blob_name))\n",
    "        blob.bucket._client = client\n",
    "        blob.upload_from_filename(source_file_name)\n",
    "    \n",
    "    def read_and_decode(filename, reshape_dims=[IMG_HEIGHT, IMG_WIDTH]):\n",
    "        # Read the file\n",
    "        img = tf.io.read_file(filename)\n",
    "\n",
    "        # Convert the compressed string to a 3D uint8 tensor.\n",
    "        img = tf.image.decode_jpeg(img, channels=IMG_CHANNELS)\n",
    "\n",
    "        # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "        # This makes the img 1 x 224 x 224 x 3 tensor with the data type of float32\n",
    "        img = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n",
    "\n",
    "        # Resize the image to the desired size.\n",
    "        return tf.image.resize(img, reshape_dims)\n",
    "    \n",
    "    def create_embeddings_dataset(embedder, img_path):\n",
    "    \n",
    "        dataset_embeddings = []\n",
    "        ids_list = []\n",
    "        id_cat_list = []\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        list_dir = tf.io.gfile.listdir(img_path)\n",
    "        for file in list_dir:\n",
    "            img_tensor = read_and_decode(img_path + \"/\" + file, [IMG_WIDTH, IMG_HEIGHT])\n",
    "            embeddings = embedder(img_tensor)\n",
    "\n",
    "            IMAGE_ID = file.split(\".\")[0]\n",
    "            CAT = train_csv.loc[train_csv['ImgId'] == IMAGE_ID, 'categories'].item()\n",
    "\n",
    "            dataset_embeddings.extend(embeddings)\n",
    "            ids_list.append(IMAGE_ID)\n",
    "            id_cat_list.append(CAT)\n",
    "\n",
    "        dataset_embeddings = tf.convert_to_tensor(dataset_embeddings)\n",
    "\n",
    "        end = time.time()\n",
    "        elapsed_time = round((end - start), 2)\n",
    "        logging.info(f'Elapsed time writting embeddings: {elapsed_time} seconds\\n')\n",
    "\n",
    "        # return dataset_filenames, dataset_embeddings, ids_list, id_cat_list\n",
    "        return dataset_embeddings, ids_list, id_cat_list\n",
    "    \n",
    "    # ==============================================================================\n",
    "    # Download TF Hub model\n",
    "    # ==============================================================================\n",
    "    layers = [\n",
    "        hub.KerasLayer(\n",
    "            f\"{TF_HUB_MODEL_DIR}\",\n",
    "            input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),\n",
    "            trainable=False,\n",
    "            name='mobilenet_embedding'),\n",
    "        tf.keras.layers.Flatten()\n",
    "    ]\n",
    "    model = tf.keras.Sequential(\n",
    "        layers, name='visual_embedding'\n",
    "    )\n",
    "    \n",
    "    # ==============================================================================\n",
    "    # create embedding vectors\n",
    "    # ==============================================================================\n",
    "    dataset_embeddings, dataset_ids, dataset_id_cats = create_embeddings_dataset(\n",
    "        lambda x: model.predict(x),\n",
    "        IMG_PATH,\n",
    "    )\n",
    "    \n",
    "    logging.info(f\"Shape of embeddings dataset: {dataset_embeddings.shape}\\n\")\n",
    "    logging.info(f\"dataset_ids: {dataset_ids[:3]}\\n\")\n",
    "    logging.info(f\"dataset_id_cats: {dataset_id_cats[:3]}\\n\")\n",
    "    \n",
    "    cleaned_embs = [x.numpy() for x in dataset_embeddings] #clean up the output\n",
    "    cleaned_id_cats = [x for x in dataset_id_cats] #clean up the output\n",
    "    cleaned_ids = [x for x in dataset_ids] #clean up the output\n",
    "    \n",
    "    # ==============================================================================\n",
    "    # write json index\n",
    "    # ==============================================================================\n",
    "    \n",
    "    with open(f\"{index_json_name}\", \"w\") as f:\n",
    "        counter = 0 \n",
    "        for img_id, vector, img_cat in zip(cleaned_ids, cleaned_embs, cleaned_id_cats):\n",
    "            f.write('{\"id\":\"' + str(img_id) + '\",')\n",
    "            f.write('\"embedding\":[' + \",\".join(str(x).strip() for x in list(vector)) + '],')\n",
    "            f.write('\"restricts\":[{\"namespace\":\"category\",\"allow\":[\"' + str(img_cat) + '\"]},') #,\n",
    "            f.write('{\"namespace\":\"tag_1\",\"allow\":['+ ('\"even\"' if counter % 2 == 0 else '\"odd\"') + ']}]}\\n')\n",
    "            counter+=1\n",
    "        f.close()\n",
    "        \n",
    "        \n",
    "    _upload_blob_gcs(emb_index_gcs_uri, f\"{index_json_name}\", f\"{index_json_name}\")\n",
    "    \n",
    "    # embedding_index_file_uri = f'{FILTER_INDEX_DIR}/{index_json_name}'\n",
    "    embedding_index_file_uri = f'{emb_index_gcs_uri}/{index_json_name}'\n",
    "    logging.info(\"embedding_index_file_uri:\", embedding_index_file_uri)\n",
    "\n",
    "    return(\n",
    "        f'{embedding_index_file_uri}',\n",
    "        f'{emb_index_gcs_uri}', # 'gs://{BUCKET}/indexes/{VERSION}'\n",
    "      # f'{save_path}',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7a8aff-37b3-4119-8c74-0436e567aadb",
   "metadata": {},
   "source": [
    "## Create ME Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2fafa918-995e-460c-a523-54a0de14a7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/pipes/create_ann_index.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{PIPELINES_SUB_DIR}/create_ann_index.py\n",
    "\n",
    "import kfp\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, component, Metrics)\n",
    "\n",
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=[\n",
    "        'google-cloud-aiplatform==1.18.1',\n",
    "        # 'google-cloud-storage',\n",
    "    ],\n",
    ")\n",
    "def create_ann_index(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    version: str, \n",
    "    staging_bucket: str,\n",
    "    vpc_network_name: str,\n",
    "    emb_index_gcs_uri: str,\n",
    "    dimensions: int,\n",
    "    ann_index_display_name: str,\n",
    "    approximate_neighbors_count: int,\n",
    "    distance_measure_type: str,\n",
    "    leaf_node_embedding_count: int,\n",
    "    leaf_nodes_to_search_percent: int, \n",
    "    ann_index_description: str,\n",
    "    ann_index_labels: Dict, \n",
    ") -> NamedTuple('Outputs', [\n",
    "    ('ann_index_resource_uri', str),\n",
    "    ('ann_index', Artifact),\n",
    "]):\n",
    "    import logging\n",
    "    from google.cloud import aiplatform as vertex_ai\n",
    "    from datetime import datetime\n",
    "    import time\n",
    "\n",
    "    vertex_ai.init(\n",
    "        project=project,\n",
    "        location=location,\n",
    "    )\n",
    "    \n",
    "    TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    \n",
    "    ENDPOINT = \"{}-aiplatform.googleapis.com\".format(location)\n",
    "    NETWORK_NAME = vpc_network_name\n",
    "    INDEX_DIR_GCS = emb_index_gcs_uri\n",
    "    PARENT = \"projects/{}/locations/{}\".format(project, location)\n",
    "\n",
    "    logging.info(\"ENDPOINT: {}\".format(ENDPOINT))\n",
    "    logging.info(\"PROJECT_ID: {}\".format(project))\n",
    "    logging.info(\"REGION: {}\".format(location))\n",
    "    \n",
    "    # ==============================================================================\n",
    "    # Create Index \n",
    "    # ==============================================================================\n",
    "\n",
    "    start = time.time()\n",
    "        \n",
    "    tree_ah_index = vertex_ai.MatchingEngineIndex.create_tree_ah_index(\n",
    "        display_name=f'{ann_index_display_name}-{TIMESTAMP}',\n",
    "        contents_delta_uri=f'{emb_index_gcs_uri}/', # emb_index_gcs_uri,\n",
    "        dimensions=dimensions,\n",
    "        approximate_neighbors_count=approximate_neighbors_count,\n",
    "        distance_measure_type=distance_measure_type,\n",
    "        leaf_node_embedding_count=leaf_node_embedding_count,\n",
    "        leaf_nodes_to_search_percent=leaf_nodes_to_search_percent,\n",
    "        description=ann_index_description,\n",
    "        labels=ann_index_labels,\n",
    "        # sync=True,\n",
    "    )\n",
    "\n",
    "    end = time.time()\n",
    "    elapsed_time = round((end - start), 2)\n",
    "    logging.info(f'Elapsed time creating index: {elapsed_time} seconds\\n')\n",
    "    \n",
    "    ann_index_resource_uri = tree_ah_index.resource_name\n",
    "    logging.info(\"ann_index_resource_uri:\", ann_index_resource_uri) \n",
    "\n",
    "    return (\n",
    "      f'{ann_index_resource_uri}',\n",
    "      tree_ah_index,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4888fa07-5d50-4107-81ae-7f7730cc8ea9",
   "metadata": {},
   "source": [
    "## Create Brute Force Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "27e85a4b-b614-46a8-844b-598d2d098687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/pipes/create_brute_force_index.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{PIPELINES_SUB_DIR}/create_brute_force_index.py\n",
    "\n",
    "import kfp\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, component, Metrics)\n",
    "\n",
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=[\n",
    "        'google-cloud-aiplatform==1.18.1',\n",
    "        # 'google-cloud-storage',\n",
    "    ],\n",
    ")\n",
    "def create_brute_force_index(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    version: str,\n",
    "    staging_bucket: str,\n",
    "    vpc_network_name: str,\n",
    "    emb_index_gcs_uri: str,\n",
    "    dimensions: int,\n",
    "    brute_force_index_display_name: str,\n",
    "    approximate_neighbors_count: int,\n",
    "    distance_measure_type: str,\n",
    "    brute_force_index_description: str,\n",
    "    brute_force_index_labels: Dict,\n",
    ") -> NamedTuple('Outputs', [\n",
    "    ('brute_force_index_resource_uri', str),\n",
    "    ('brute_force_index', Artifact),\n",
    "]):\n",
    "\n",
    "    import logging\n",
    "    from google.cloud import aiplatform as vertex_ai\n",
    "    from datetime import datetime\n",
    "    import time\n",
    "\n",
    "    vertex_ai.init(\n",
    "        project=project,\n",
    "        location=location,\n",
    "    )\n",
    "    \n",
    "    TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    \n",
    "    ENDPOINT = \"{}-aiplatform.googleapis.com\".format(location)\n",
    "    NETWORK_NAME = vpc_network_name\n",
    "    INDEX_DIR_GCS = emb_index_gcs_uri\n",
    "    PARENT = \"projects/{}/locations/{}\".format(project, location)\n",
    "\n",
    "    logging.info(\"ENDPOINT: {}\".format(ENDPOINT))\n",
    "    logging.info(\"PROJECT_ID: {}\".format(project))\n",
    "    logging.info(\"REGION: {}\".format(location))\n",
    "    \n",
    "    # ==============================================================================\n",
    "    # Create Index \n",
    "    # ==============================================================================\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    brute_force_index = vertex_ai.MatchingEngineIndex.create_brute_force_index(\n",
    "        display_name=f'{brute_force_index_display_name}-{TIMESTAMP}',\n",
    "        contents_delta_uri=f'{emb_index_gcs_uri}/', # emb_index_gcs_uri,\n",
    "        dimensions=dimensions,\n",
    "        # approximate_neighbors_count=approximate_neighbors_count,\n",
    "        distance_measure_type=distance_measure_type,\n",
    "        description=brute_force_index_description,\n",
    "        labels=brute_force_index_labels,\n",
    "        # sync=True,\n",
    "    )\n",
    "    brute_force_index_resource_uri = brute_force_index.resource_name\n",
    "    print(\"brute_force_index_resource_uri:\",brute_force_index_resource_uri) \n",
    "\n",
    "    return (\n",
    "      f'{brute_force_index_resource_uri}',\n",
    "      brute_force_index,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2bd1a0-b45c-4c20-b138-086f4c5786f1",
   "metadata": {},
   "source": [
    "## Create IndexEndpoint with VPC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdf1058-9946-426e-a9aa-586d398250e4",
   "metadata": {},
   "source": [
    "### Create ANN Index Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be2cc05c-84f4-436d-af7b-8733aaa1b720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/pipes/create_ann_index_endpoint_vpc.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{PIPELINES_SUB_DIR}/create_ann_index_endpoint_vpc.py\n",
    "\n",
    "import kfp\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, component, Metrics)\n",
    "\n",
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=[\n",
    "        'google-cloud-aiplatform==1.18.1',\n",
    "        # 'google-cloud-storage',\n",
    "    ],\n",
    ")\n",
    "def create_ann_index_endpoint_vpc(\n",
    "    ann_index_artifact: Input[Artifact],\n",
    "    project: str,\n",
    "    project_number: str,\n",
    "    location: str,\n",
    "    version: str,\n",
    "    vpc_network_name: str,\n",
    "    ann_index_endpoint_display_name: str,\n",
    "    ann_index_endpoint_description: str,\n",
    ") -> NamedTuple('Outputs', [\n",
    "    ('vpc_network_resource_uri', str),\n",
    "    ('ann_index_endpoint_resource_uri', str),\n",
    "    ('ann_index_endpoint', Artifact),\n",
    "    ('ann_index_endpoint_display_name', str),\n",
    "]):\n",
    "\n",
    "    import logging\n",
    "    from google.cloud import aiplatform as vertex_ai\n",
    "    from datetime import datetime\n",
    "    import time\n",
    "\n",
    "    vertex_ai.init(\n",
    "        project=project,\n",
    "        location=location,\n",
    "    )\n",
    "    \n",
    "    TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "    vpc_network_resource_uri = f'projects/{project_number}/global/networks/{vpc_network_name}'\n",
    "    logging.info(f\"vpc_network_resource_uri: {vpc_network_resource_uri}\")\n",
    "\n",
    "    ann_index_endpoint = vertex_ai.MatchingEngineIndexEndpoint.create(\n",
    "        display_name=f'{ann_index_endpoint_display_name}',\n",
    "        description=ann_index_endpoint_description,\n",
    "        network=vpc_network_resource_uri,\n",
    "    )\n",
    "    ann_index_endpoint_resource_uri = ann_index_endpoint.resource_name\n",
    "    logging.info(f\"ann_index_endpoint_resource_uri: {ann_index_endpoint_resource_uri}\")\n",
    "\n",
    "    return (\n",
    "        f'{vpc_network_resource_uri}',\n",
    "        f'{ann_index_endpoint_resource_uri}',\n",
    "        ann_index_endpoint,\n",
    "        f'{ann_index_endpoint_display_name}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a1cb2f-9595-4107-b1dd-5d6c8caf9807",
   "metadata": {},
   "source": [
    "### Create BF Index Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "269fb0a3-a065-49ae-8224-494e4c2fd791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/pipes/create_brute_index_endpoint_vpc.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{PIPELINES_SUB_DIR}/create_brute_index_endpoint_vpc.py\n",
    "\n",
    "import kfp\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, component, Metrics)\n",
    "\n",
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=[\n",
    "        'google-cloud-aiplatform==1.18.1',\n",
    "        # 'google-cloud-storage',\n",
    "    ],\n",
    ")\n",
    "def create_brute_index_endpoint_vpc(\n",
    "    bf_index_artifact: Input[Artifact],\n",
    "    project: str,\n",
    "    project_number: str,\n",
    "    location: str,\n",
    "    version: str,\n",
    "    vpc_network_name: str,\n",
    "    brute_index_endpoint_display_name: str,\n",
    "    brute_index_endpoint_description: str,\n",
    ") -> NamedTuple('Outputs', [\n",
    "    ('vpc_network_resource_uri', str),\n",
    "    ('brute_index_endpoint_resource_uri', str),\n",
    "    ('brute_index_endpoint', Artifact),\n",
    "    ('brute_index_endpoint_display_name', str),\n",
    "]):\n",
    "\n",
    "    import logging\n",
    "    from google.cloud import aiplatform as vertex_ai\n",
    "    from datetime import datetime\n",
    "    import time\n",
    "\n",
    "    vertex_ai.init(\n",
    "        project=project,\n",
    "        location=location,\n",
    "    )\n",
    "    \n",
    "    TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "    vpc_network_resource_uri = f'projects/{project_number}/global/networks/{vpc_network_name}'\n",
    "    logging.info(f\"vpc_network_resource_uri: {vpc_network_resource_uri}\")\n",
    "\n",
    "    brute_index_endpoint = vertex_ai.MatchingEngineIndexEndpoint.create(\n",
    "        display_name=f'{brute_index_endpoint_display_name}',\n",
    "        description=brute_index_endpoint_description,\n",
    "        network=vpc_network_resource_uri,\n",
    "    )\n",
    "    brute_index_endpoint_resource_uri = brute_index_endpoint.resource_name\n",
    "    logging.info(f\"brute_index_endpoint_resource_uri: {brute_index_endpoint_resource_uri}\")\n",
    "\n",
    "    return (\n",
    "      f'{vpc_network_resource_uri}',\n",
    "      f'{brute_index_endpoint_resource_uri}',\n",
    "      brute_index_endpoint,\n",
    "      f'{brute_index_endpoint_display_name}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4637c9-d799-4a4e-8033-20e4c7e25bb6",
   "metadata": {},
   "source": [
    "## Deploy Indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ac4ad5-9e73-48e4-86aa-f20cf9068d06",
   "metadata": {},
   "source": [
    "### Deploy ANN Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "44f67e0b-968b-4d6a-ac3a-64942b6a071c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/pipes/deploy_ann_index.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{PIPELINES_SUB_DIR}/deploy_ann_index.py\n",
    "\n",
    "import kfp\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, component, Metrics)\n",
    "\n",
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=[\n",
    "        'google-cloud-aiplatform==1.18.1'\n",
    "    ]\n",
    ")\n",
    "def deploy_ann_index(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    version: str,\n",
    "    staging_bucket: str,\n",
    "    deployed_ann_index_name: str,\n",
    "    ann_index_resource_uri: str,\n",
    "    index_endpoint_resource_uri: str,\n",
    ") -> NamedTuple('Outputs', [\n",
    "    ('index_endpoint_resource_uri', str),\n",
    "    ('ann_index_resource_uri', str),\n",
    "    ('deployed_ann_index_name', str),\n",
    "    ('deployed_ann_index', Artifact),\n",
    "]):\n",
    "  \n",
    "    import logging\n",
    "    from google.cloud import aiplatform as vertex_ai\n",
    "    from datetime import datetime\n",
    "    import time\n",
    "\n",
    "    vertex_ai.init(\n",
    "        project=project,\n",
    "        location=location,\n",
    "    )\n",
    "    TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    VERSION = version\n",
    "    \n",
    "    ann_index = vertex_ai.MatchingEngineIndex(\n",
    "      index_name=ann_index_resource_uri\n",
    "    )\n",
    "    ann_index_resource_uri = ann_index.resource_name\n",
    "\n",
    "    index_endpoint = vertex_ai.MatchingEngineIndexEndpoint(\n",
    "      index_endpoint_resource_uri\n",
    "    )\n",
    "\n",
    "    index_endpoint = index_endpoint.deploy_index(\n",
    "      index=ann_index, \n",
    "      deployed_index_id=f'{deployed_ann_index_name}' #-{TIMESTAMP}'\n",
    "    )\n",
    "\n",
    "    print(index_endpoint.deployed_indexes)\n",
    "\n",
    "    return (\n",
    "      f'{index_endpoint_resource_uri}',\n",
    "      f'{ann_index_resource_uri}',\n",
    "      f'{deployed_ann_index_name}',\n",
    "      ann_index,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f540054-acb8-4fff-aeee-40c87fbc6c05",
   "metadata": {},
   "source": [
    "### Deploy BF Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "16f2cdbb-5178-4607-8288-62d419e3b6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/pipes/deploy_brute_index.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{PIPELINES_SUB_DIR}/deploy_brute_index.py\n",
    "\n",
    "import kfp\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, component, Metrics)\n",
    "\n",
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=[\n",
    "        'google-cloud-aiplatform==1.18.1',\n",
    "        # 'google-cloud-storage',\n",
    "    ],\n",
    ")\n",
    "def deploy_brute_index(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    version: str,\n",
    "    staging_bucket: str,\n",
    "    deployed_brute_force_index_name: str,\n",
    "    brute_force_index_resource_uri: str,\n",
    "    index_endpoint_resource_uri: str,\n",
    ") -> NamedTuple('Outputs', [\n",
    "    ('index_endpoint_resource_uri', str),\n",
    "    ('brute_force_index_resource_uri', str),\n",
    "    ('deployed_brute_force_index_name', str),\n",
    "    ('deployed_brute_force_index', Artifact),\n",
    "]):\n",
    "  \n",
    "    import logging\n",
    "    from google.cloud import aiplatform as vertex_ai\n",
    "    from datetime import datetime\n",
    "    import time\n",
    "\n",
    "    vertex_ai.init(\n",
    "        project=project,\n",
    "        location=location,\n",
    "    )\n",
    "    TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "    brute_index = vertex_ai.MatchingEngineIndex(\n",
    "        index_name=brute_force_index_resource_uri\n",
    "    )\n",
    "    brute_force_index_resource_uri = brute_index.resource_name\n",
    "\n",
    "    index_endpoint = vertex_ai.MatchingEngineIndexEndpoint(index_endpoint_resource_uri)\n",
    "\n",
    "    index_endpoint = index_endpoint.deploy_index(\n",
    "        index=brute_index, \n",
    "        deployed_index_id=f'{deployed_brute_force_index_name}', #-{TIMESTAMP}'\n",
    "    )\n",
    "\n",
    "    logging.info(index_endpoint.deployed_indexes)\n",
    "\n",
    "    return (\n",
    "      f'{index_endpoint_resource_uri}',\n",
    "      f'{brute_force_index_resource_uri}',\n",
    "      f'{deployed_brute_force_index_name}', #-{TIMESTAMP}',\n",
    "      brute_index,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06730637-f5cc-4212-a2e6-17cc5b5beb0b",
   "metadata": {},
   "source": [
    "# Build & Compile Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b671fc7-b44b-4764-a81f-975b2d48c76a",
   "metadata": {},
   "source": [
    "## Pipe Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5c418b55-a85a-49a4-be7d-b520be6842d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIPELINE_TAG: retail-visual-similarity-v1\n"
     ]
    }
   ],
   "source": [
    "PIPELINE_VERSION = 'v1' # pipeline code\n",
    "PIPELINE_TAG = f'retail-visual-similarity-{PIPELINE_VERSION}'\n",
    "print(\"PIPELINE_TAG:\", PIPELINE_TAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "13120251-e17b-46bd-9aa8-b7938cf79336",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pipes import generate_candidates, create_ann_index, \\\n",
    "                      create_brute_force_index, create_ann_index_endpoint_vpc, create_brute_index_endpoint_vpc, \\\n",
    "                      deploy_ann_index, deploy_brute_index\n",
    "@kfp.v2.dsl.pipeline(\n",
    "    name=f'{VERSION}-{PIPELINE_TAG}'.replace('_', '-')\n",
    ")\n",
    "def pipeline(\n",
    "    project: str,\n",
    "    project_number: str,\n",
    "    location: str,\n",
    "    version: str,\n",
    "    # run: str,\n",
    "    staging_bucket: str,\n",
    "    bucket: str,\n",
    "    vpc_network_name: str,\n",
    "    images_gcs_uri: str,\n",
    "    emb_index_gcs_uri: str,\n",
    "    dimensions: int,\n",
    "    ann_index_display_name: str,\n",
    "    approximate_neighbors_count: int,\n",
    "    distance_measure_type: str,\n",
    "    leaf_node_embedding_count: int,\n",
    "    leaf_nodes_to_search_percent: int, \n",
    "    ann_index_description: str,\n",
    "    ann_index_labels: Dict,\n",
    "    brute_force_index_display_name: str,\n",
    "    brute_force_index_description: str,\n",
    "    brute_force_index_labels: Dict,\n",
    "    ann_index_endpoint_display_name: str,\n",
    "    ann_index_endpoint_description: str,\n",
    "    brute_index_endpoint_display_name: str,\n",
    "    brute_index_endpoint_description: str,\n",
    "    deployed_ann_index_name: str,\n",
    "    deployed_brute_force_index_name: str,\n",
    "    dest_folder: str,\n",
    "    index_json_name: str,\n",
    "):\n",
    "    \n",
    "    from google_cloud_pipeline_components.types import artifact_types\n",
    "    # ========================================================================\n",
    "    # TODO: data prep\n",
    "    # ========================================================================\n",
    "    \n",
    "    # TODO\n",
    "    \n",
    "    # ========================================================================\n",
    "    # generate embeddings\n",
    "    # ========================================================================\n",
    "    generate_candidates_op = (\n",
    "        generate_candidates.generate_candidates(\n",
    "            project=project,\n",
    "            location=location,\n",
    "            version=version,\n",
    "            # run=run,\n",
    "            bucket=bucket,\n",
    "            images_gcs_uri=images_gcs_uri,\n",
    "            dest_folder=dest_folder,\n",
    "            emb_index_gcs_uri=emb_index_gcs_uri,\n",
    "            index_json_name=index_json_name,\n",
    "        )\n",
    "        .set_display_name(\"Generate Catalog Embeddings\")\n",
    "        .set_caching_options(True)\n",
    "    )\n",
    "\n",
    "    create_ann_index_op = (\n",
    "        create_ann_index.create_ann_index(\n",
    "            project=project,\n",
    "            location=location,\n",
    "            version=version,\n",
    "            staging_bucket=staging_bucket,\n",
    "            vpc_network_name=vpc_network_name,\n",
    "            emb_index_gcs_uri=generate_candidates_op.outputs['embedding_index_gcs_dir'],\n",
    "            dimensions=dimensions,\n",
    "            ann_index_display_name=ann_index_display_name,\n",
    "            approximate_neighbors_count=approximate_neighbors_count,\n",
    "            distance_measure_type=distance_measure_type,\n",
    "            leaf_node_embedding_count=leaf_node_embedding_count,\n",
    "            leaf_nodes_to_search_percent=leaf_nodes_to_search_percent, \n",
    "            ann_index_description=ann_index_description,\n",
    "            ann_index_labels=ann_index_labels,\n",
    "        )\n",
    "        .set_display_name(\"Create ANN Index\")\n",
    "        # .after(generate_candidates_op)\n",
    "        .set_caching_options(True)\n",
    "    )\n",
    "\n",
    "    create_brute_force_index_op = (\n",
    "        create_brute_force_index.create_brute_force_index(\n",
    "            project=project,\n",
    "            location=location,\n",
    "            version=version,\n",
    "            staging_bucket=staging_bucket,\n",
    "            vpc_network_name=vpc_network_name,\n",
    "            emb_index_gcs_uri=generate_candidates_op.outputs['embedding_index_gcs_dir'],\n",
    "            dimensions=dimensions,\n",
    "            brute_force_index_display_name=brute_force_index_display_name,\n",
    "            approximate_neighbors_count=approximate_neighbors_count,\n",
    "            distance_measure_type=distance_measure_type,\n",
    "            brute_force_index_description=brute_force_index_description,\n",
    "            brute_force_index_labels=brute_force_index_labels,\n",
    "        )\n",
    "        .set_display_name(\"Create BF Index\")\n",
    "        # .after(generate_candidates_op)\n",
    "        .set_caching_options(True)\n",
    "    )\n",
    "\n",
    "    # ========================================================================\n",
    "    # Create Index Endpoint\n",
    "    # ========================================================================\n",
    "\n",
    "    \n",
    "    create_ann_index_endpoint_vpc_op = (\n",
    "        create_ann_index_endpoint_vpc.create_ann_index_endpoint_vpc(\n",
    "            ann_index_artifact=create_ann_index_op.outputs['ann_index'],\n",
    "            project=project,\n",
    "            project_number=project_number,\n",
    "            version=version,\n",
    "            location=location,\n",
    "            vpc_network_name=vpc_network_name,\n",
    "            ann_index_endpoint_display_name=ann_index_endpoint_display_name,\n",
    "            ann_index_endpoint_description=ann_index_endpoint_description,\n",
    "        )\n",
    "        .set_display_name(\"Create ANN Index Endpoint\")\n",
    "        .after(generate_candidates_op)\n",
    "    )\n",
    "        \n",
    "    create_brute_index_endpoint_vpc_op = (\n",
    "        create_brute_index_endpoint_vpc.create_brute_index_endpoint_vpc(\n",
    "            bf_index_artifact=create_brute_force_index_op.outputs['brute_force_index'],\n",
    "            project=project,\n",
    "            project_number=project_number,\n",
    "            version=version,\n",
    "            location=location,\n",
    "            vpc_network_name=vpc_network_name,\n",
    "            brute_index_endpoint_display_name=brute_index_endpoint_display_name,\n",
    "            brute_index_endpoint_description=brute_force_index_description,\n",
    "        )\n",
    "        .set_display_name(\"Create BF Index Endpoint\")\n",
    "        .after(generate_candidates_op)\n",
    "    )\n",
    "\n",
    "    # ========================================================================\n",
    "    # Deploy Indexes\n",
    "    # ========================================================================\n",
    "\n",
    "    deploy_ann_index_op = (\n",
    "        deploy_ann_index.deploy_ann_index(\n",
    "            project=project,\n",
    "            location=location,\n",
    "            version=version,\n",
    "            staging_bucket=staging_bucket,\n",
    "            # vpc_network_resource_uri=create_ann_index_endpoint_vpc_op.outputs['vpc_network_resource_uri'],\n",
    "            deployed_ann_index_name=deployed_ann_index_name,\n",
    "            ann_index_resource_uri=create_ann_index_op.outputs['ann_index_resource_uri'],\n",
    "            index_endpoint_resource_uri=create_ann_index_endpoint_vpc_op.outputs['ann_index_endpoint_resource_uri'],\n",
    "        )\n",
    "        .set_display_name(\"Deploy ANN Index\")\n",
    "        .set_caching_options(True)\n",
    "    )\n",
    "\n",
    "    deploy_brute_index_op = (\n",
    "        deploy_brute_index.deploy_brute_index(\n",
    "            project=project,\n",
    "            location=location,\n",
    "            version=version,\n",
    "            staging_bucket=staging_bucket,\n",
    "            # vpc_network_resource_uri=create_brute_index_endpoint_vpc_op.outputs['vpc_network_resource_uri'],\n",
    "            deployed_brute_force_index_name=deployed_brute_force_index_name,\n",
    "            brute_force_index_resource_uri=create_brute_force_index_op.outputs['brute_force_index_resource_uri'],\n",
    "            index_endpoint_resource_uri=create_brute_index_endpoint_vpc_op.outputs['brute_index_endpoint_resource_uri'],\n",
    "        )\n",
    "        .set_display_name(\"Deploy BF Index\")\n",
    "        .set_caching_options(True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242750bf-a98e-4c5a-87f5-39ab1b9f55d9",
   "metadata": {},
   "source": [
    "## Compile pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8a141726-ca5d-46b9-929a-830289354628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://retail-products-kaggle/pipelines_root/v5/run-20221104003701'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PIPELINES_FILEPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b38c509e-3c24-4dc1-89f5-29ff9804c738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://custom_container_pipeline_spec.json [Content-Type=application/json]...\n",
      "/ [1 files][ 48.2 KiB/ 48.2 KiB]                                                \n",
      "Operation completed over 1 objects/48.2 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "kfp.v2.compiler.Compiler().compile(\n",
    "  pipeline_func=pipeline, \n",
    "  package_path='custom_container_pipeline_spec.json', #PIPELINES_FILEPATH, # PIPELINE_JSON_SPEC_PATH # 'custom_container_pipeline_spec.json',\n",
    ")\n",
    "\n",
    "!gsutil cp custom_container_pipeline_spec.json $PIPELINES_FILEPATH/pipeline_spec.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1d8361-72ae-407f-83f0-50446125c148",
   "metadata": {},
   "source": [
    "### pipe args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8063a875-edad-4fcc-8030-c0a5b34a6651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil du gs://retail-products-kaggle/dataset/train/train | wc -l # 16551\n",
    "# !gsutil du gs://retail-products-kaggle/data-full/train/train | wc -l # 42001\n",
    "# !gsutil du gs://retail-products-kaggle/dataset/test/test | wc -l # 6368\n",
    "# !gsutil du gs://retail-products-kaggle/data-full/test/test | wc -l # 6368"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b39f9284-47c4-4561-8be3-0a394a5b78b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "PREFIX = 'test-filters'\n",
    "PROJECT_ID = 'hybrid-vertex'\n",
    "project_number='934903580331'\n",
    "LOCATION = 'us-central1'\n",
    "\n",
    "# if not declared\n",
    "PIPE_USER = 'jtott'\n",
    "# BUCKET = 'retail-products-kaggle'\n",
    "# BUCKET_URI = f'gs://{BUCKET}'\n",
    "# DATA_FOLDER = 'data-full'\n",
    "\n",
    "staging_bucket=f'gs://{BUCKET}/staging'\n",
    "\n",
    "emb_index_gcs_uri = f'gs://{BUCKET}/indexes/{VERSION}'\n",
    "vpc_network_name='ucaip-haystack-vpc-network'\n",
    "images_gcs_uri=f'gs://{BUCKET}/{DATA_FOLDER}/train/train'\n",
    "index_json_name = \"retail_kaggle_embeddings.json\"\n",
    "\n",
    "\n",
    "# Indexes\n",
    "DIMENSIONS = 1280\n",
    "approximate_neighbors_count=50\n",
    "distance_measure_type=\"DOT_PRODUCT_DISTANCE\"\n",
    "leaf_node_embedding_count=500\n",
    "leaf_nodes_to_search_percent=7\n",
    "\n",
    "ann_index_display_name = f'ann_{DIMENSIONS}_index_{VERSION}'\n",
    "brute_force_index_display_name = f'brute_force_{DIMENSIONS}_index_{VERSION}'\n",
    "\n",
    "ann_index_description=f'Kaggle Retail Product MobileNet_v2 ANN index {VERSION}-{PIPELINE_VERSION}'\n",
    "brute_force_index_description=f\"Kaggle Retail Product MobileNet_v2 (brute force)-{VERSION}-{PIPELINE_VERSION}\"\n",
    "\n",
    "\n",
    "ann_index_labels={'version': f'{VERSION}',\n",
    "                  'pipeline_version': f'{PIPELINE_VERSION}',}\n",
    "\n",
    "brute_force_index_labels={'version': f'{VERSION}',\n",
    "                          'pipeline_version': f'{PIPELINE_VERSION}',}\n",
    "\n",
    "index_endpoint_display_name=f'index_endpoint_{VERSION}'\n",
    "index_endpoint_description=\"index endpoint description\"\n",
    "\n",
    "\n",
    "ann_index_endpoint_description = f'ann {index_endpoint_description}'\n",
    "brute_index_endpoint_description = f'bf {index_endpoint_description}'\n",
    "\n",
    "ann_index_endpoint_display_name = f'ann {index_endpoint_display_name}'\n",
    "brute_index_endpoint_display_name = f'bf {index_endpoint_display_name}'\n",
    "\n",
    "\n",
    "\n",
    "deployed_ann_index_name=f'ann_{DIMENSIONS}_deployed_index_{VERSION}'\n",
    "deployed_brute_force_index_name=f'brute_force_{DIMENSIONS}_deployed_index_{VERSION}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1246d105-1cf5-4f8b-a2d2-ddf106c5ea5f",
   "metadata": {},
   "source": [
    "### Submit pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "73e8e9e1-6e8c-4018-9952-19c1f5f156e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "See the Pipeline job <a href=\"https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/v5-retail-visual-similarity-v1-20221104003727?project=hybrid-vertex\" target=\"_blank\" >here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "overwrite = True\n",
    "# overwrite = False\n",
    "\n",
    "from kfp.v2.google.client import AIPlatformClient\n",
    "\n",
    "pipeline_client = AIPlatformClient(\n",
    "  project_id=PROJECT_ID,\n",
    "  region=LOCATION,\n",
    ")\n",
    "\n",
    "if not PIPELINES.get('train') or overwrite:\n",
    "    response = pipeline_client.create_run_from_job_spec(\n",
    "        job_spec_path='custom_container_pipeline_spec.json',\n",
    "        network=f'projects/{project_number}/global/networks/{vpc_network_name}', # set to same VPC as index\n",
    "        # service_account=SERVICE_ACCOUNT, # <--- TODO: Uncomment if needed\n",
    "        parameter_values={\n",
    "            'project': PROJECT_ID,\n",
    "            'project_number': project_number,\n",
    "            'location': LOCATION,\n",
    "            'version': VERSION,\n",
    "            # 'run': RUN,\n",
    "            'staging_bucket': staging_bucket,\n",
    "            'vpc_network_name': vpc_network_name,\n",
    "            'images_gcs_uri': images_gcs_uri,\n",
    "            'emb_index_gcs_uri': emb_index_gcs_uri,\n",
    "            'bucket': BUCKET,\n",
    "            'dest_folder': DATA_FOLDER,\n",
    "            'dimensions': DIMENSIONS,\n",
    "            'ann_index_display_name': ann_index_display_name,\n",
    "            'approximate_neighbors_count': approximate_neighbors_count,\n",
    "            'distance_measure_type': distance_measure_type,\n",
    "            'leaf_node_embedding_count': leaf_node_embedding_count,\n",
    "            'leaf_nodes_to_search_percent': leaf_nodes_to_search_percent, \n",
    "            'ann_index_description': ann_index_description,\n",
    "            'ann_index_labels': ann_index_labels,\n",
    "            'brute_force_index_display_name': brute_force_index_display_name,\n",
    "            'brute_force_index_description': brute_force_index_description,\n",
    "            'brute_force_index_labels': brute_force_index_labels,\n",
    "            'ann_index_endpoint_description': ann_index_endpoint_description,\n",
    "            'brute_index_endpoint_description': brute_index_endpoint_description,\n",
    "            # 'index_endpoint_display_name': index_endpoint_display_name,\n",
    "            # 'index_endpoint_description': index_endpoint_description,\n",
    "            'deployed_ann_index_name': deployed_ann_index_name,\n",
    "            'deployed_brute_force_index_name': deployed_brute_force_index_name,\n",
    "            'ann_index_endpoint_display_name': ann_index_endpoint_display_name,\n",
    "            'brute_index_endpoint_display_name': brute_index_endpoint_display_name,\n",
    "            # 'test_imgs_gcs_dir': test_imgs_gcs_dir,\n",
    "            # 'model_endpoint_name': model_endpoint_name,\n",
    "            # 'model_display_name': model_display_name,\n",
    "            # 'serving_container_image_uri': serving_container_image_uri,\n",
    "            # 'traffic_percentage': traffic_percentage,\n",
    "            # 'serving_machine_type': serving_machine_type,\n",
    "            # 'serving_min_replica_count': serving_min_replica_count,\n",
    "            # 'serving_max_replica_count': serving_max_replica_count,\n",
    "            'index_json_name':index_json_name,\n",
    "        },\n",
    "        pipeline_root=f'{PIPELINES_FILEPATH}',\n",
    "    )\n",
    "    PIPELINES['train'] = response['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed477f6-8796-423f-a951-0840f11fb9a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m95",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m95"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
